<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <title>Worker-Based WebCodecs Test (with Logging)</title>
  <style>
    video {
      width: 100vw;
      height: auto;
      display: block;
    }
  </style>
  <!--   
        <script type="text/javascript" src="https://jan-ivar.github.io/polyfills/mediastreamtrackprocessor.js"></script>
        <script type="text/javascript" src="https://jan-ivar.github.io/polyfills/mediastreamtrackgenerator.js"></script>
         -->
</head>

<body>
  <button id="start">Start</button> polyfilled to work in all browsers!<br><br>
  <video
    id="video1"
    width="240"
    height="180"
    autoplay
    muted
  ></video>
  <video
    id="video2"
    width="240"
    height="180"
    autoplay
    muted
  ></video>

  <script type="module">

    // polyfill via https://jan-ivar.github.io/polyfills/mediastreamtrackprocessor.js
    if (!self.MediaStreamTrackProcessor) {
      console.log("Polyfilling MediaStreamTrackProcessor");
      self.MediaStreamTrackProcessor = class MediaStreamTrackProcessor {
        constructor({ track }) {
          if (track.kind == "video") {
            this.readable = new ReadableStream({
              async start(controller) {
                this.video = document.createElement("video");
                this.video.srcObject = new MediaStream([track]);
                await Promise.all([this.video.play(), new Promise(r => this.video.onloadedmetadata = r)]);
                this.track = track;
                this.canvas = new OffscreenCanvas(this.video.videoWidth, this.video.videoHeight);
                this.ctx = this.canvas.getContext('2d', { desynchronized: true });
                this.t1 = performance.now();
              },
              async pull(controller) {
                while (performance.now() - this.t1 < 1000 / track.getSettings().frameRate) {
                  await new Promise(r => requestAnimationFrame(r));
                }
                this.t1 = performance.now();
                this.ctx.drawImage(this.video, 0, 0);
                controller.enqueue(new VideoFrame(this.canvas, { timestamp: this.t1 }));
              }
            });
          }
        }
      };
    }


    // polyfill via https://jan-ivar.github.io/polyfills/mediastreamtrackgenerator.js

    if (!window.MediaStreamTrackGenerator) {
      console.log("Polyfilling MediaStreamTrackGenerator");
      window.MediaStreamTrackGenerator = class MediaStreamTrackGenerator {
        constructor({ kind }) {
          if (kind == "video") {
            const canvas = document.createElement("canvas");
            const ctx = canvas.getContext('2d', { desynchronized: true });
            const track = canvas.captureStream().getVideoTracks()[0];
            track.writable = new WritableStream({
              write(frame) {
                canvas.width = frame.displayWidth;
                canvas.height = frame.displayHeight;
                ctx.drawImage(frame, 0, 0, canvas.width, canvas.height);
                frame.close();
              }
            });
            return track;
          }
        }
      };
    }

    start.onclick = async () => {
      video1.srcObject = await navigator.mediaDevices.getUserMedia({ video: true });
      const mstp = new MediaStreamTrackProcessor({ track: video1.srcObject.getVideoTracks()[0] });
      const mstg = new MediaStreamTrackGenerator({ kind: "video" });
      video2.srcObject = new MediaStream([mstg]);
      await mstp.readable.pipeThrough(new TransformStream({ transform })).pipeTo(mstg.writable);
    };

    const canvas = new OffscreenCanvas(640, 480);
    const ctx = canvas.getContext('2d', { desynchronized: true });
    ctx.translate(canvas.width, 0);
    ctx.scale(-1, 1);

    function transform(frame, controller) {
      ctx.drawImage(frame, 0, 0);
      const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
      const { data } = imageData;
      for (let i = 0; i < data.length; i += 4) {
        const r = data[i], g = data[i + 1], b = data[i + 2];
        data[i] = 0.393 * r + 0.769 * g + 0.189 * b;
        data[i + 1] = 0.349 * r + 0.686 * g + 0.168 * b;
        data[i + 2] = 0.272 * r + 0.534 * g + 0.131 * b;
      }
      ctx.putImageData(imageData, 0, 0);
      controller.enqueue(new VideoFrame(canvas, { timestamp: frame.timestamp }));
      frame.close();
    }

  </script>
</body>

</html>